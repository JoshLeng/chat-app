    // src/services/aiService.js
    import { GoogleGenerativeAI } from '@google/generative-ai';

    const GEMINI_API_KEY = 'AIzaSyA4xAf0WRJj7_jhD0kKk5d7moQYuZbWHhg';

    export class AIService {
      static genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
      
      
      static modelosPrioritarios = [
   
        'gemini-2.0-flash-lite-preview',           
        'gemini-2.0-flash-lite-preview-02-05',     
        
      
        'gemini-2.5-flash',                        
        'gemini-2.5-flash-preview-05-20',        
        
        
        'gemini-2.0-flash-thinking-exp',         
        'gemini-2.0-flash-thinking-exp-01-21',     
        
      
        'gemini-2.0-pro-exp',                      
        'gemini-exp-1206',                         
      ];

      static async procesarPrompt(prompt) {
        let ultimoError = null;
        
        // Probar modelos en orden de prioridad
        for (const modelo of this.modelosPrioritarios) {
          try {
            console.log(`üîÆ Probando: ${modelo}`);
            
            const respuesta = await this.probarModeloEspecifico(modelo, prompt);
            console.log(`‚úÖ √âxito con: ${modelo}`);
            return respuesta;
            
          } catch (error) {
            console.log(`‚ùå Fall√≥ ${modelo}:`, error.message);
            ultimoError = error;
            
            // Si es error de quota, continuar con siguiente modelo
            if (error.message.includes('quota') || error.message.includes('429')) {
              continue;
            }
            
            // Si es otro error, continuar igual
            continue;
          }
        }
        
        // Si todos fallan
        return this.mensajeErrorFinal(ultimoError);
      }

      static async probarModeloEspecifico(modelo, prompt) {
  try {
    const model = this.genAI.getGenerativeModel({ 
      model: modelo,
      generationConfig: {
        maxOutputTokens: 800,
        temperature: 0.7,
      }
    });
    
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const texto = response.text();
    
    // ‚úÖ VALIDAR QUE LA RESPUESTA NO EST√â VAC√çA
    if (!texto || texto.trim() === '') {
      throw new Error('Respuesta vac√≠a recibida de Gemini');
    }
    
    return texto;
    
  } catch (error) {
    console.error(`‚ùå Error con modelo ${modelo}:`, error);
    throw error;
  }
}
      static mensajeErrorFinal(error) {
        const mensajeBase = `ü§ñ **Asistente IA - L√≠mites Alcanzados**

    He intentado todos los modelos disponibles pero todos han alcanzado sus l√≠mites gratuitos.

    *Los modelos m√°s econ√≥micos probados:*
    ‚ö° **Gemini 2.0 Flash-Lite** (m√°s econ√≥mico)
    ‚ö° **Gemini 2.5 Flash** 
    ‚ö° **Varios modelos experimentales**

    *Pr√≥ximos pasos:*
    ‚è∞ **Espera 1-2 minutos** - los l√≠mites se reinician autom√°ticamente
    üîÑ **Prueba de nuevo** - funcionar√° pronto
    üí¨ **Chat normal** - sigue disponible

    `;

        if (error?.message.includes('quota')) {
          return mensajeBase + `*Error espec√≠fico:* L√≠mite de cuota excedido`;
        }
        
        return mensajeBase + `*Estado:* Todos los modelos probados est√°n limitados temporalmente`;
      }

      // M√©todo para ver qu√© modelos estamos usando
      static getModelosActivos() {
        return this.modelosPrioritarios.slice(0, 3); // Mostrar primeros 3
      }
    }